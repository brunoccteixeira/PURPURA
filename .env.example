# ===========================
# LLM Configuration
# ===========================

# Set to "1" to use mock responses (no API calls)
LLM_MOCK=1

# OpenAI Configuration (required if LLM_MOCK is not set)
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-4o-mini
# Optional: Organization and Project IDs
# OPENAI_ORG_ID=org_xxx
# OPENAI_PROJECT_ID=proj_xxx

# LLM timeout in seconds
LLM_TIMEOUT=120

# ===========================
# Trino Configuration
# ===========================

TRINO_HOST=localhost
TRINO_PORT=8080
TRINO_USER=bruno
TRINO_CATALOG=lake
TRINO_SCHEMA=ifrs

# ===========================
# Iceberg Configuration
# ===========================

# S3/MinIO warehouse location
ICEBERG_WAREHOUSE=s3a://purpura/lake/ifrs/
